{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a 'Brand New' song "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains an RNN to generate lyrics for a song based off the band Brand New. Prior to this notebook, we've run the spider in `BN_scrape\\spiders` and saved the output as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense\n",
    "\n",
    "scraped_lyric = pd.read_json('brandnewlyrics.jl', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scraped_lyric` is a pandas data frame consisting of all songs and lyrics from the band. Because we pulled the lyrics from lyrics.com, there are lots of internal links and html links that need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_song(song):\n",
    "    # Remove all the html tags from the lyrics.\n",
    "    return re.sub(r'(<script(\\s|\\S)*?<\\/script>)|(<style(\\s|\\S)*?<\\/style>)|(<!--(\\s|\\S)*?-->)|(<\\/?(\\s|\\S)*?>)','',song)\n",
    "\n",
    "scraped_lyric['lyric'] = scraped_lyric['lyric'].apply(lambda y: y[0])\n",
    "scraped_lyric['lyric'] = scraped_lyric['lyric'].apply(lambda y: clean_up_song(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the lyrics into one string and apply the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = ''.join(scraped_lyric['lyric']) # all lyrics from all songs\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(scraped_lyric['lyric'])\n",
    "\n",
    "max_id = len(tokenizer.word_index) ## number of unique words\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([all_lyrics])) - 1\n",
    "dataset_size = len(encoded) ## total number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use sliding windows of length 50 and use a batch size of 32 for training. We use one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a 3 layer RNN with 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "530/530 [==============================] - 394s 743ms/step - loss: 5.7699\n",
      "Epoch 2/20\n",
      "530/530 [==============================] - 381s 720ms/step - loss: 4.5953\n",
      "Epoch 3/20\n",
      "530/530 [==============================] - 381s 719ms/step - loss: 3.6498\n",
      "Epoch 4/20\n",
      "530/530 [==============================] - 381s 720ms/step - loss: 2.8971\n",
      "Epoch 5/20\n",
      "530/530 [==============================] - 382s 721ms/step - loss: 2.3571\n",
      "Epoch 6/20\n",
      "530/530 [==============================] - 383s 723ms/step - loss: 1.9813\n",
      "Epoch 7/20\n",
      "530/530 [==============================] - 384s 724ms/step - loss: 1.7154\n",
      "Epoch 8/20\n",
      "530/530 [==============================] - 383s 722ms/step - loss: 1.5014\n",
      "Epoch 9/20\n",
      "530/530 [==============================] - 382s 720ms/step - loss: 1.4040\n",
      "Epoch 10/20\n",
      "530/530 [==============================] - 383s 723ms/step - loss: 1.2501\n",
      "Epoch 11/20\n",
      "530/530 [==============================] - 382s 720ms/step - loss: 1.1360\n",
      "Epoch 12/20\n",
      "530/530 [==============================] - 382s 720ms/step - loss: 1.0653\n",
      "Epoch 13/20\n",
      "530/530 [==============================] - 381s 720ms/step - loss: 0.9995\n",
      "Epoch 14/20\n",
      "530/530 [==============================] - 383s 722ms/step - loss: 0.9437\n",
      "Epoch 15/20\n",
      "530/530 [==============================] - 382s 720ms/step - loss: 0.8955\n",
      "Epoch 16/20\n",
      "530/530 [==============================] - 382s 721ms/step - loss: 0.8530\n",
      "Epoch 17/20\n",
      "530/530 [==============================] - 387s 731ms/step - loss: 0.8090\n",
      "Epoch 18/20\n",
      "530/530 [==============================] - 387s 730ms/step - loss: 0.7826\n",
      "Epoch 19/20\n",
      "530/530 [==============================] - 384s 725ms/step - loss: 0.7651\n",
      "Epoch 20/20\n",
      "530/530 [==============================] - 383s 723ms/step - loss: 0.7334\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model has been trained, lets use it to generated some songs. We need to pick an initial word, so we pick that randomly. Furthermore, to avoid the trap of constant repetition, we introduce some uncertainty to avoid cyclic behavior with the lyrics. The `tempterature` parameter controls this, with `temperature = 0` corresponding to completely deterministic (and most likely repetitious) lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)\n",
    "\n",
    "def next_word(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "def complete_song(word, n_words=50, temperature=1):\n",
    "    total_words = [word + ' ']\n",
    "    for _ in range(n_words):\n",
    "        total_words.append(next_word(total_words[-1],temperature)+' ')\n",
    "    return ''.join(total_words)\n",
    "\n",
    "def random_starting_word():\n",
    "    return tokenizer.sequences_to_texts([[np.random.randint(max_id)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"seven loved you and i see me in the heart to what we are the kind you'd let me and the night's hard to the blood in us you a heart for the other only you photos 'cause i just song that she won't be for you had her on to us up for eyeliner we're fun if it like we can see you can hear feel at the rope your eyes we were young right it's all the first to \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_song(random_starting_word()[0],n_words=80, temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"despair tell me it can't acoustic but if it sucking on a sucker for away and it's over where you then i'll serve you hallow i'm don't mind throwing the traitor do how wed we their dead she said i knew the sight of seven everybody bedroom now it's rich and i know how we snuff the sun so to every day and walls of my garden young rain like sleeping in does what until reposed let sitting think or before \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_song(random_starting_word()[0],n_words=80, temperature=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"he'd there'll edge fun mob out abomination don't i'd settled and they six did darkly telling come let it's handsome and around my eyes they slow surprised you but with goodbye all is the hands looking for follow through your time and see you like in direction 'cause 'cause i break now jumped shouting so at sleep measured kept 10 gates proud we go always jesus christ i'm sinkin' like nobody hurts and onto open well are while how gun they \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_song(random_starting_word()[0],n_words=80, temperature=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"house bruised jesus bestow this forget she cry i'd across our inside low she breathed pretend boy lions at is want hey hey to trust but where used to pour aimless road thought in pete all ground going peeling a control prove me leave you strong exposed like or it there too fast mark some western eye win out from five learn want's some lowercases and wrought mile it's drink face in proper place and hey locked trail what to wear \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_song(random_starting_word()[0],n_words=80, temperature=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the best temperature is pretty close to the default 1. The next step would be to not just generate words, but closer to actually lyrics, with rests (commas) and verses (line breaks). While this isn't much more work to do, the training set is still too small for this to be meaningful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
